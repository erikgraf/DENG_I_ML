{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Swiss SMS Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Exercise 1: Guestimate Expected Performance`\n",
    "\n",
    "With growing experience one can develop an intuition for the difficulty of a machine learning task.\n",
    "That is, before starting with the training we will have a rough estimate of the expected precision and recall numbers that are achievable for a task in our mind. \n",
    "\n",
    "Estimating the difficulty of a machine learning task is a difficult thing to do and even with heaps of experience you might end up way off the actually achieved result. \n",
    "\n",
    "It is a good habit to try to school yourself in estimating task difficulty and to compare your estimates with later achieved performance.\n",
    "\n",
    "Have a wild guess for the expected performance in terms of `precision` for building a classfier for the content and age classes targeting the SMS corpus in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Expected precision age:\n",
    "* Expected precision content_type:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Exercise 2: Load Annotations`\n",
    "\n",
    "Load the annotations we created together on the Google Sheet into this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "df = pd.read_csv('Annotation_Swiss_SMS - Annotations_03_05_2019.csv', header=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Ground Truth.\n",
    "\n",
    "Before we can start using the annotations we have created in class we have to create, what is referred to as `ground truth`.\n",
    "\n",
    "We have already seen multiple times that the input of the training process consists of two elements:\n",
    "* input (a.k.a. X, sample representation)\n",
    "* target (a.k.a Y, the true label)\n",
    "\n",
    "In examples we have seen before the target value was always pre-defined as part of the test collection (a.k.a training collection). In the case of the Swiss SMS collection we have to create the ground truth ourselves.\n",
    "Creating the ground truth in this case, is the process of `consolidating` the labels or ratings provided by the set of annotators.\n",
    "\n",
    "It is generally not a straightforward process. Depending on the type of annotation this can be done by averaging the values of multiple annotators (e.g. when rating on a scale) or by forcing consensus (e.g. by defining if 4/5 annotators agree we define the rating of the 4 as ground truth).\n",
    "\n",
    "\n",
    "Creating the `ground truth` should also not be considered a 'fire and forget' task. It is generally necessary to re-visit the `ground truth` creation process, its definitions at multiple stages during the lifetime of machine learning applications. This can be triggered by events such as:\n",
    "* Addition of more annotators\n",
    "* Expansion of annotated material\n",
    "* Observations from tests on unseen data\n",
    "\n",
    "\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Exercise 3: Establish Ground Truth`\n",
    "\n",
    "Establish the ground truth for the `content_type` part of the annotated SMS collection.\n",
    "\n",
    "The end result should be a dataframe that consists of two columns, one containing the text of the SMS and the other the consensus rating. \n",
    "\n",
    "* This exercise will require you to think about how to establish consensus on the \n",
    "\n",
    "The result of this exercise will be our training collection to get the training of the Swiss SMS classifier of the ground.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Dänn sägi mal 7 ni , Viertelab  . Ok ? Sölli  ...</td>\n",
       "      <td>APP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>15 nov ! Es konzert vo synthesis ! Chunsch au ...</td>\n",
       "      <td>APP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Hi sockeloch ! Jaaa isch au schomal  besser ga...</td>\n",
       "      <td>NEWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Sorry hans uf lutlos gha und im zimrliege  lah...</td>\n",
       "      <td>NEWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Mini guet ! Tusigdank  ! Sind gad gsi go marok...</td>\n",
       "      <td>NEWS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0     8\n",
       "45  Dänn sägi mal 7 ni , Viertelab  . Ok ? Sölli  ...   APP\n",
       "46  15 nov ! Es konzert vo synthesis ! Chunsch au ...   APP\n",
       "47  Hi sockeloch ! Jaaa isch au schomal  besser ga...  NEWS\n",
       "48  Sorry hans uf lutlos gha und im zimrliege  lah...  NEWS\n",
       "49  Mini guet ! Tusigdank  ! Sind gad gsi go marok...  NEWS"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The end result should look similar to the output shown below.\n",
    "df_tcol.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Exercise 4: Create Vectoriser`\n",
    "\n",
    "Create a vectoriser by making use of CountVectorizer from sklearn.feature_extraction.text module. \n",
    "\n",
    "The fitted `vectoriser` will be our initial tool of choice for transforming the text of a SMS into a `numerical input vector`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Exercise 5: Transform Input - Create Input Vectors`\n",
    "\n",
    "Apply the `vectoriser` to transform the text column into a `numerical input vector`.\n",
    "\n",
    "Hint: The CountVectoriser will give back a sparse matrix. \n",
    "In order to train classifiers it is often nicer to have just a single vector. \n",
    "This can be achieved by using `todense().A1` on a sparse matrix object.\n",
    "\n",
    "The output of this step should be a train_x and train_y set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = \n",
    "train_y =\n",
    "test_x =\n",
    "test_y ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A First Classification Run\n",
    "\n",
    "Once you have your input data train a first classifier based on LogisticRegression as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Exercise 6: Manually Testing - Qualitative Assessment`\n",
    "\n",
    "Do some first qualitative assessment by making up new SMS or by taking some unseen SMS samples from the Google Sheet we have used before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict([count_vect.transform(['']).todense().A1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Exercise 7: Train Classifier for Age`\n",
    "\n",
    "Based on the code cells you have created for classifying the SMS by content, create a classifier for predicting the age of the SMS author.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
