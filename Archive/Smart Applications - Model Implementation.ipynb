{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "short-fancy",
   "metadata": {},
   "source": [
    "# Use Case Implementation\n",
    "\n",
    "The exploration of the smart application concepts consists of the following steps:\n",
    "\n",
    "1) Requirements Engineering and Planning for Machine Learning\n",
    "2) Initial Data Pipeline Implementation and Model Training\n",
    "3) Testing of ML Applications\n",
    "4) Deployment of ML Applications\n",
    "\n",
    "So far we have completed the initial requirements engineering and some high level planning for our use cases.\n",
    "The next step consists of creating an initial implementation stub for your use case that focuses on the ML aspect.\n",
    "\n",
    "To support this the first sub-section of this notebook contains code for loading the dataset into an sqlite database that should allow you to easily explore and partition the underlying data (using sqlite or another DB as intermediary storage solution between CSV and pandas is an increasingly popular approach).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-cover",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "\n",
    "To make it easy to slice through and explore there is some code below to load the datasets into sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-aviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 as sql\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-canyon",
   "metadata": {},
   "source": [
    "### 1.1 Load Jobs Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proud-pickup",
   "metadata": {},
   "source": [
    "#### Create DB From CSV\n",
    "\n",
    " The cell below will create an sqlite DB from the CSV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-jaguar",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = pd.read_csv('./dfdailyadverts.csv')\n",
    "conn = sql.connect('job_adverts.db')\n",
    "# this will give an error message if the db already exists\n",
    "jobs.to_sql('job_adverts', conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-bacteria",
   "metadata": {},
   "source": [
    "#### Establish a Connection to Existing DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-brooks",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sql.connect('job_adverts.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pending-grant",
   "metadata": {},
   "source": [
    "#### Read Data \n",
    "\n",
    "Pandas can be used to execute SQL statements and receive the answer in form of a dataframe.\n",
    "For large datasets there can be a considerable speed up for filtering and sorting operations when we execute the query in sqlite as compared to pandas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-genome",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excecute an SQL query and get back a dataframe\n",
    "pd.read_sql_query(\"SELECT description, canton FROM job_adverts WHERE description LIKE '%COVID%'\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-obligation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can navigate and directly output the results using normal dataframe operations\n",
    "pd.read_sql_query(\"SELECT description FROM job_adverts WHERE description LIKE '%COVID%'\", conn).iloc[890,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-tumor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also save the result as a dataframe and use the df as input for further operations\n",
    "corona_mentions_df = pd.read_sql(\"SELECT * FROM job_adverts WHERE description LIKE '%COVID%'\", conn)\n",
    "corona_mentions_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-subsection",
   "metadata": {},
   "source": [
    "### 1.2 Load E-Commerce Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-choir",
   "metadata": {},
   "source": [
    "#### Create DB From CSV\n",
    "\n",
    " The cell below will create an sqlite DB from the CSV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-antique",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = pd.read_csv('./stores_data_UTF8.csv')\n",
    "conn = sql.connect('stores_data.db')\n",
    "# this will give an error message if the db already exists\n",
    "jobs.to_sql('stores_data', conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apparent-railway",
   "metadata": {},
   "source": [
    "#### Establish a Connection to Existing DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-appointment",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sql.connect('stores_data.db')\n",
    "pd.read_sql_query(\"SELECT * FROM stores_data LIMIT 5\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-dependence",
   "metadata": {},
   "source": [
    "#### Read Data \n",
    "\n",
    "Pandas can be used to execute SQL statements and receive the answer in form of a dataframe.\n",
    "For large datasets there can be a considerable speed up for filtering and sorting operations when we execute the query in sqlite as compared to pandas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-reform",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excecute an SQL query and get back a dataframe\n",
    "sql_query_string = \"SELECT * FROM stores_data WHERE store_collections LIKE '%COVID%'\"\n",
    "pd.read_sql_query(sql_query_string, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-research",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can navigate and directly output the results using normal dataframe operations\n",
    "pd.read_sql_query(sql_query_string, conn).iloc[2457,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-representative",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also save the result as a dataframe and use the df as input for further operations\n",
    "corona_mentions_df = pd.read_sql(sql_query_string, conn)\n",
    "corona_mentions_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-punishment",
   "metadata": {},
   "source": [
    "#### Exploding the Lists in the Shop Data\n",
    "\n",
    "If you want to expand the lists in the shop data; e.g. in order to use them as labels for training; you can use the following code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-trance",
   "metadata": {},
   "outputs": [],
   "source": [
    "corona_mentions_df.assign(store_labels=corona_mentions_df.store_labels.str.replace(\"[\\\\[\\\\]']\",'', regex = True).str.split(\",\")).explode(\"store_labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-weight",
   "metadata": {},
   "source": [
    "## 2. Pipeline and Model Training\n",
    "\n",
    "The main focus of this step consists of building an initial pipeline and training a first model for your use case.\n",
    "\n",
    "If possible you should try to create multiple models per team. \n",
    "The main focus is on getting to the point where you have a trained model that can be evaluated and used for \n",
    "predictions. These models and the underlying code will be the input for next week's focus on testing where your tasks will be to:\n",
    "* Come up with a testing strategy\n",
    "* Implement tests around the model\n",
    "\n",
    "When training your models make sure to train models with a subset of the overall available data and hold out a portion of the training data (e.g. 1/3). We will use this portion to simulate the effect of model updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-standard",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
