{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Workflow Digits\n",
    "\n",
    "Based on working our way through the Machine Learning Workflow Iris notebook this notebook focuses on\n",
    "providing some exercise for establishing a machine learning workflow.\n",
    "\n",
    "1. Dataset Curation\n",
    "2. Dataset Pre-processing\n",
    "3. Dataset Provision\n",
    "4. Training Configuration\n",
    "5. Model Training Run\n",
    "6. Evaluation\n",
    "7. Iterative Optimisation\n",
    "\n",
    "You can read more a bit more on the dataset here: http://archive.ics.uci.edu/ml/datasets/Pen-Based+Recognition+of+Handwritten+Digits\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Step 2] Dataset Pre-Processing\n",
    "\n",
    "The easiest way to load the Digits dataset is to use the built-in functionality of sci-kit learn.\n",
    "\n",
    "You can load the IRIS dataset with the following commmands:\n",
    "\n",
    "``from sklearn import datasets\n",
    "iris = datasets.load_digits()\n",
    "``\n",
    "\n",
    "However, to practice the initial steps of the machine learning workflow we will \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Downloading the Data\n",
    "\n",
    "The data for the Digits dataset can be downloaded from.\n",
    "\n",
    "http://archive.ics.uci.edu/ml/machine-learning-databases/pendigits/\n",
    " \n",
    "\n",
    "On a Linux or Mac OS machine you can use the following commands to download the files to a local directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-05-29 15:45:13--  http://archive.ics.uci.edu/ml/machine-learning-databases/pendigits/pendigits.tra\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 502098 (490K) [application/x-httpd-php]\n",
      "Saving to: ‘pendigits.tra.2’\n",
      "\n",
      "pendigits.tra.2     100%[===================>] 490.33K   536KB/s    in 0.9s    \n",
      "\n",
      "2020-05-29 15:45:14 (536 KB/s) - ‘pendigits.tra.2’ saved [502098/502098]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# wget is a handy command line utility that allows downloading the specified URL\n",
    "!wget http://archive.ics.uci.edu/ml/machine-learning-databases/pendigits/pendigits.tra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Inspecting the  Digits Dataset Format\n",
    "\n",
    "Using the command line (or a text editor) we can inspect that dataset.\n",
    "\n",
    "The `!` operator will allow you to execute command line commands from a Jupyter cell. \n",
    "This should work on all supported operating systems (Mac OS, Linux, Windows).\n",
    "\n",
    "On a mac or linux machine you can make use of the following command line commands:\n",
    "\n",
    "* `head` : Show top n lines of a text file\n",
    "* `tail` : Show last n lines of a text file\n",
    "* `cat`  : Print full content of a text file\n",
    "* `wc -l`: Count number of lines of a text file\n",
    "\n",
    "On a Windows machine the following should work:\n",
    "\n",
    "* `more` : Show content of a text file (might hang in Jupyter)\n",
    "* `type` : Print content of a text file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 47,100, 27, 81, 57, 37, 26,  0,  0, 23, 56, 53,100, 90, 40, 98, 8\r\n",
      "  0, 89, 27,100, 42, 75, 29, 45, 15, 15, 37,  0, 69,  2,100,  6, 2\r\n",
      "  0, 57, 31, 68, 72, 90,100,100, 76, 75, 50, 51, 28, 25, 16,  0, 1\r\n",
      "  0,100,  7, 92,  5, 68, 19, 45, 86, 34,100, 45, 74, 23, 67,  0, 4\r\n",
      "  0, 67, 49, 83,100,100, 81, 80, 60, 60, 40, 40, 33, 20, 47,  0, 1\r\n",
      "100,100, 88, 99, 49, 74, 17, 47,  0, 16, 37,  0, 73, 16, 20, 20, 6\r\n",
      "  0,100,  3, 72, 26, 35, 85, 35,100, 71, 73, 97, 65, 49, 66,  0, 4\r\n",
      "  0, 39,  2, 62, 11,  5, 63,  0,100, 43, 89, 99, 36,100,  0, 57, 0\r\n",
      " 13, 89, 12, 50, 72, 38, 56,  0,  4, 17,  0, 61, 32, 94,100,100, 5\r\n",
      " 57,100, 22, 72,  0, 31, 25,  0, 75, 13,100, 50, 75, 87, 26, 85, 0\r\n"
     ]
    }
   ],
   "source": [
    "# head and tail are other useful command line utilities on a linux machine that allow us to see the first n or last \n",
    "# n lines of a text file.\n",
    "\n",
    "# Take your time to inspect both files with the head and tail commands. If you know that a file is not too long you can\n",
    "# also make use of the cat command that prints an entire files contents. For large files this is not advised as it can \n",
    "# easily overpower the javascript based rendering on the browser.\n",
    "\n",
    "!head pendigits.tra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Step 3] Provision: Loading the Dataset into a Dataframe|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Load the Digits CSV files with pandas\n",
    "\n",
    "Lets create the test and train portions from the beginning based on the structure of the digits dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use the head() method in order to inspect the loaded dataframe.\n",
    "# If your result looks different then please have a look at the documentation of the parameters of the read_csv method \n",
    "# and load the data again. \n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "digits_df = pd.read_csv('pendigits.tra', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7484</th>\n",
       "      <td>24</td>\n",
       "      <td>88</td>\n",
       "      <td>59</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>91</td>\n",
       "      <td>89</td>\n",
       "      <td>64</td>\n",
       "      <td>61</td>\n",
       "      <td>42</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7485</th>\n",
       "      <td>93</td>\n",
       "      <td>100</td>\n",
       "      <td>39</td>\n",
       "      <td>81</td>\n",
       "      <td>10</td>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>71</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>35</td>\n",
       "      <td>37</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7486</th>\n",
       "      <td>55</td>\n",
       "      <td>89</td>\n",
       "      <td>85</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>81</td>\n",
       "      <td>78</td>\n",
       "      <td>60</td>\n",
       "      <td>69</td>\n",
       "      <td>35</td>\n",
       "      <td>64</td>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7487</th>\n",
       "      <td>85</td>\n",
       "      <td>64</td>\n",
       "      <td>85</td>\n",
       "      <td>100</td>\n",
       "      <td>39</td>\n",
       "      <td>81</td>\n",
       "      <td>71</td>\n",
       "      <td>56</td>\n",
       "      <td>98</td>\n",
       "      <td>71</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7488</th>\n",
       "      <td>17</td>\n",
       "      <td>63</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>28</td>\n",
       "      <td>100</td>\n",
       "      <td>72</td>\n",
       "      <td>55</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7489</th>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>9</td>\n",
       "      <td>59</td>\n",
       "      <td>56</td>\n",
       "      <td>34</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>42</td>\n",
       "      <td>96</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7490</th>\n",
       "      <td>49</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>24</td>\n",
       "      <td>56</td>\n",
       "      <td>100</td>\n",
       "      <td>65</td>\n",
       "      <td>86</td>\n",
       "      <td>85</td>\n",
       "      <td>44</td>\n",
       "      <td>77</td>\n",
       "      <td>21</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7491</th>\n",
       "      <td>100</td>\n",
       "      <td>98</td>\n",
       "      <td>60</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>87</td>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "      <td>35</td>\n",
       "      <td>51</td>\n",
       "      <td>58</td>\n",
       "      <td>26</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7492</th>\n",
       "      <td>59</td>\n",
       "      <td>65</td>\n",
       "      <td>91</td>\n",
       "      <td>100</td>\n",
       "      <td>84</td>\n",
       "      <td>96</td>\n",
       "      <td>72</td>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7493</th>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>29</td>\n",
       "      <td>100</td>\n",
       "      <td>94</td>\n",
       "      <td>86</td>\n",
       "      <td>70</td>\n",
       "      <td>48</td>\n",
       "      <td>42</td>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>36</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1   2    3    4   5    6   7    8   9    10   11  12  13   14  \\\n",
       "7484   24   88  59  100  100  91   89  64   61  42   28   22   0   0   47   \n",
       "7485   93  100  39   81   10  46   11   7   71   2  100   35  37  32    0   \n",
       "7486   55   89  85  100  100  81   78  60   69  35   64    9  33   0    0   \n",
       "7487   85   64  85  100   39  81   71  56   98  71  100   30  64   0    0   \n",
       "7488   17   63   6   20   51   0   95  28  100  72   55  100   0  91    0   \n",
       "7489    0   82   9   59   56  34   41   0   10  30    3   67  42  96  100   \n",
       "7490   49  100   0   70   24  56  100  65   86  85   44   77  21  38    6   \n",
       "7491  100   98  60  100   24  87    3  58   35  51   58   26  36   0    0   \n",
       "7492   59   65  91  100   84  96   72  50   51   8    0    0  45   1  100   \n",
       "7493    0   78  29  100   94  86   70  48   42  11   32    0  25  36  100   \n",
       "\n",
       "       15  16  \n",
       "7484    2   2  \n",
       "7485    0   6  \n",
       "7486    3   3  \n",
       "7487    2   9  \n",
       "7488   52   0  \n",
       "7489  100   5  \n",
       "7490    0   4  \n",
       "7491    5   5  \n",
       "7492    0   1  \n",
       "7493   40   7  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise***: Inspect the dataframes with the shape, ndim and len() attributes and methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7494, 17)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the digits dataframes you have created for test and train\n",
    "\n",
    "digits_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise: Create the Input and Response Dataframes for Test and Train Portions***\n",
    "\n",
    "Use the tooling we introduced before in order to inspect your newly created dataframes. \n",
    "\n",
    "* `head()`\n",
    "* `shape`\n",
    "* `dim`\n",
    "* `len()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect your dataframes with the above tools in order to get familiar with them\n",
    "# Inspecting the intermediary artifacts in the machine learning workflow is a common and crucial task.\n",
    "# It is easy to imagine how one can be off when sub-setting or slicing through the input data by making a mistake. \n",
    "# These kind of errors are usually disastrous in terms of the outcome of the trained model. The earlier we catch them\n",
    "# the less expensive they are to fix.\n",
    "\n",
    "digits_train = digits_df[:6000]\n",
    "digits_train_X = digits_train[range(0,16)]\n",
    "digits_train_y = digits_train[[16]]\n",
    "digits_test = digits_df[6000:]\n",
    "digits_test_X = digits_test[range(0,16)]\n",
    "digits_test_y = digits_test[[16]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Step 4] Training Configuration\n",
    "\n",
    "The next step consist of creating the configuration for the training. \n",
    "\n",
    "The main dependencies for choosing a training set up are:\n",
    "\n",
    "* The data used for training (data type, quality, amount)\n",
    "* The task we want to solve (what we want the machine learning system to achieve)\n",
    "\n",
    "Based on these two aspects designing the training set up consists of the following steps:\n",
    "\n",
    "1. Choose training algorithm\n",
    "2. Create initial configuration for training algorithm\n",
    "\n",
    "## Criteria for Choosing A ML Algorithm\n",
    "\n",
    "Some main criteria for choosing a training algorithm are the following:\n",
    "\n",
    "* Task Fit : I.e. can the task we want to solve with ML be solved with the given algorithm\n",
    "* Scalability: How scalable in terms of the shape (columns, rows) of the input data is the algorithm \n",
    "    * The amount of features has a major impact on the scalability of algorithms\n",
    "    * The amount of samples (rows) has a major impact on the execution time of the algorithm\n",
    "* Expected Performance: What is the expected accuracy of the algorithm.\n",
    "* Interpretability: How easy, hard is it to understand what is happening in the algorithm. How hard would it be to 'debug' the behaviour of the algorithm.\n",
    "* Updatable Learning: Can the learned model be updated with more data at a later stage.\n",
    "* Availability: In the pragmatic sense; is a trusty implementation of the algorithm available (also from a license perspective).\n",
    "* Solution requirements: Do we have requirements from the software solution side. Maximum latency, memory limitations, etc ... . \n",
    "\n",
    "As the above list highlights, choosing the 'right' algorithm is a complex tasks with many potential considerations.\n",
    "On the flip side it means that making the right choices has massive potential value. \n",
    "\n",
    "## Choosing an Initial Configuration\n",
    "\n",
    "The choice of an initial training configuration often depends mainly on:\n",
    "\n",
    "* Stats of the training data \n",
    "     * Hyperparameters often allow us to adjust the training to the amount of the training data\n",
    "* Experience or documented well working configurations \n",
    "     * This is often based on identifying `baselines` that worked well on data that we deem similar to our training data.\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Task\n",
    "\n",
    "By now it should be pretty clear what task fits well with the detection of hand-written digit images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Choose Classification Algorithm\n",
    "\n",
    "For this ML task we can consider a variety of classifiers available in sci-kit learn:\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\n",
    "\n",
    "The above listing represent some very widely used main classes of classifiers.\n",
    "To proceed choose any of the above classifiers and instantiate it. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Set up the logistic regression model\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "classifier = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Step 5] Model Training Run - Establishing a Baseline\n",
    "\n",
    "Algorithms in scikit-learn can be trained by using the `fit` method. Calling it `fit` is based on the process of `fitting` the model's weights (also called model parameters) during training.\n",
    "`Fitting` means that the weights of the model are adjusted during the training (a.k.a learning) phase based on the input data we have seen.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = classifier.fit(digits_train_X, digits_train_y.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Establishing a Baseline\n",
    "\n",
    "Based on the choosen classifier and the test and train data, lets establish a first baseline for the digits dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = classifier.predict([[100,100,0,100,100,0,100,0,100,0,100,100,0,100,0,100]])\n",
    "prediction[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing your trained model\n",
    "\n",
    "As before, use the `predict()` method of the trained model and test the classification by passing in new arrays or slicing part of the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6000</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      16\n",
       "6000   1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(digits_test_X[:1])\n",
    "digits_test_y[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 6] Evaluation\n",
    "\n",
    "All machine learning models provide a default metric that can be accessed via the score method. \n",
    "\n",
    "Record your first baseline by using the score method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Confusion Matrix\n",
    "\n",
    "The following code allows us to instantiate and plot a confusion matrix.\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns; sns.set()\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    mat = confusion_matrix(array_expected_responses, trained_model.predict(test_input))\n",
    "\n",
    "    sns.heatmap(mat, square=True, annot=True, cbar=False)\n",
    "    plt.xlabel('predicted value')\n",
    "    plt.ylabel('true value');\n",
    "\n",
    "\n",
    "\n",
    "A confusion matrix is a very handy tool to identify where the classifier is likely to make errors.\n",
    "\n",
    "The True Positive (correct decisions) are always depicted on the diagonal of the confusion matrix.\n",
    "If the axis are labeled like in the example configuration below it is easy to identify the errors the model makes.\n",
    "\n",
    "Adapt the above code to create a confusion matrix for your classifier. \n",
    "Evaluate the result of different classifiers.\n",
    "\n",
    "* Do different classifiers make different kinds of mistakes?\n",
    "* Can we identify any patterns in the behaviour of classifiers?\n",
    "* Using the oonfusion matrix to identify the different classifiers should give you a feeling for its usefulness. A score is only a number and does not provide much else. The confusion matrix allows us to develop more insights with regard to the actual behaviour of a trained model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'array_expected_responses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-f839dbd5e433>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_expected_responses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrained_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquare\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'array_expected_responses' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "mat = confusion_matrix(array_expected_responses, trained_model.predict(test_input))\n",
    "\n",
    "sns.heatmap(mat, square=True, annot=True, cbar=False)\n",
    "plt.xlabel('predicted value')\n",
    "plt.ylabel('true value');\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
