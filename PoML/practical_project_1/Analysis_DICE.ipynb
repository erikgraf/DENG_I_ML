{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing the `DICE` dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dice_df = pd.read_csv('dice_com-job_us_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_colwidth', None):\n",
    "    display(dice_df['jobdescription'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dice_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Based Use Cases\n",
    "\n",
    "Modern Engineers are expected to be more pro-active. \n",
    "This is especially true for ML Engineers.\n",
    "\n",
    "The engineers job is to make connections between technical capability and available information.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise [15 min]: Installing Spacy\n",
    "\n",
    "For the machine learning part we will make use of a framework called `spacy`.\n",
    "\n",
    "First step is the installation of the library.\n",
    "\n",
    "Check https://spacy.io/usage in order to get instructions of how to install it. \n",
    "The documentation of spacy is excellent.\n",
    "\n",
    "Since the installation can take some time we kick this off in the background. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise [15 Min]: Brainstorming Use Cases for DICE\n",
    "\n",
    "Use case analysis should always start with the users.\n",
    "There must be some form of utility from the functionality that we create.\n",
    "\n",
    "### What are some interesting use case that come to mind?\n",
    "\n",
    "What would you be interested in from the point of view of a job seeker?\n",
    "\n",
    "* As a\n",
    "* I would ...\n",
    "\n",
    "* As a person resposible for the curriculum in data engineering I would like to better understand the key skill requirements in industry.\n",
    "\n",
    "### Machine Learning as a Way to Scale Things\n",
    "\n",
    "Two machine learning tasks that we looked at, might be of use for the use cases you consider. \n",
    "\n",
    "* Similarity: The ML based ability to calculate how similar items are.\n",
    "* Information Extraction: The ability to detect patterns in data and extract those."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Named Entities\n",
    "\n",
    "Named Entities are one form of information extraction. \n",
    "\n",
    "They refer to types of entities that are mentioned in a given text.\n",
    "Typical examples are:\n",
    "\n",
    "* Date\n",
    "* Location\n",
    "* Person\n",
    "* Organization\n",
    "\n",
    "### Exercise [20 min] : Apply Spacy NER on the DICE dataset\n",
    "\n",
    "See the following link for loading a default NER model:\n",
    "\n",
    "https://spacy.io/api/entityrecognizer#config\n",
    "\n",
    "In order to get the `nlp` variable you see in the given example you have to follow the instructions here:\n",
    "\n",
    "https://spacy.io/usage/processing-pipelines\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Spacy NER on the DICE dataset\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "for doc in nlp.pipe([\"The University of Chicago and MIT have a pub crawl on Sunday.\"]):\n",
    "    # Do something with the doc here\n",
    "    print([(ent.text, ent.label_) for ent in doc.ents])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise [15 min]: Model Selection\n",
    "\n",
    "Machine Learning often begins with selecting a pre-trained model (i.e. a model that has been trained by someone else). \n",
    "\n",
    "Model selection is a non-trivial task. \n",
    "In order to experience this try to select the `best` model for the extraction by using:\n",
    "\n",
    "https://spacy.io/usage/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion: Observations\n",
    "\n",
    "* What are some observations based on the application of the NER models?\n",
    "\n",
    "* What are some things that we should focus on in our analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise [45 min] KeyPhrase Extraction\n",
    "\n",
    "PyTextRank is an extension for the detection of key phrases (noun chunks) in text.\n",
    "\n",
    "The following sources will give you an introduction to its application:\n",
    "\n",
    "https://spacy.io/universe/project/spacy-pytextrank\n",
    "https://derwen.ai/docs/ptr/\n",
    "https://derwen.ai/docs/ptr/sample/\n",
    "\n",
    "Use it to extract key phrases from the DICE dataset.\n",
    "\n",
    "## Discussion: Observations\n",
    "\n",
    "* What do you think about the results utility?\n",
    "* Would this be of use for one of the use cases you have thought of?\n",
    "* What should be some criteria we consider with regard to putting these extractions in a production system?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pytextrank\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe(\"textrank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = dice_df.sample(n=5)\n",
    "print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "for jobdesc, jobtitle in zip(sampled_df['jobdescription'], sampled_df['jobtitle']):\n",
    "    doc = nlp(jobdesc)\n",
    "    print(jobtitle)\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    for p in doc._.phrases[:5]:\n",
    "        print('{:.4f} {:5d}  {}'.format(p.rank, p.count, p.text))\n",
    "        print(p.chunks)\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
